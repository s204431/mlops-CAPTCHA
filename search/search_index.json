{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#documentation","title":"Documentation","text":"<p>Documentation for captcha</p>"},{"location":"backend_monitoring/","title":"Backend Monitoring","text":""},{"location":"backend_monitoring/#captcha.backend_monitoring.get_report","title":"captcha.backend_monitoring.get_report  <code>async</code>","text":"<pre><code>get_report(n: int = 5)\n</code></pre> <p>Generate and return the report.</p> Source code in <code>src/captcha/backend_monitoring.py</code> <pre><code>@app.get(\"/report\", response_class=HTMLResponse)\nasync def get_report(n: int = 5):\n    \"\"\"Generate and return the report.\"\"\"\n    prediction_data = load_latest_files(Path(\".\"), n=n)\n    run_analysis(training_data, prediction_data)\n    async with await anyio.open_file(\"monitoring.html\", encoding=\"utf-8\") as f:\n        html_content = await f.read()\n    return HTMLResponse(content=html_content, status_code=200)\n</code></pre>"},{"location":"bentoml_service/","title":"Bentoml Service","text":""},{"location":"bentoml_service/#captcha.bentoml_service.CaptchaClassifierService","title":"captcha.bentoml_service.CaptchaClassifierService","text":"<p>Captcha classifier service using ONNX model.</p> Source code in <code>src/captcha/bentoml_service.py</code> <pre><code>@bentoml.service(workers=2)\nclass CaptchaClassifierService:\n    \"\"\"Captcha classifier service using ONNX model.\"\"\"\n\n    def __init__(self) -&gt; None:\n        self.model = InferenceSession(\"onnx_model.onnx\")\n\n    @bentoml.api(\n        batchable=True,\n        batch_dim=(0, 0),\n        max_batch_size=128,\n        max_latency_ms=1000,\n    )\n    def predict(self, image: np.ndarray) -&gt; np.ndarray:\n        \"\"\"Predict the class of the input image.\"\"\"\n        request_counter.inc()\n        with request_latency.time():\n            try:\n                image_size_summary.observe(image.shape[2] * image.shape[3])\n                output = self.model.run(None, {\"input\": image.astype(np.float32)})\n                class_names = np.array(\n                    [\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"m\", \"n\", \"p\", \"w\", \"x\", \"y\"]\n                )\n                self.save_prediction_to_gcp(image, output[0][0].tolist(), class_names[np.argmax(output[0][0])])\n                return output[0]\n            except Exception as e:\n                error_counter.inc()\n                raise HTTPException(status_code=500, detail=str(e)) from e\n\n    def save_prediction_to_gcp(self, image: np.ndarray, outputs: list[float], prediction: str) -&gt; None:\n        \"\"\"Save the prediction results to GCP bucket.\"\"\"\n        client = storage.Client.create_anonymous_client()\n        bucket = client.bucket(\"mlops_captcha_monitoring\")\n        time = datetime.datetime.now(tz=datetime.UTC)\n        # Prepare prediction data\n        image = image.squeeze(0).squeeze(0)\n        image = image.flatten().tolist()\n        data = {\n            \"image\": image,\n            \"prediction\": prediction,\n            \"probability\": outputs,\n            \"timestamp\": datetime.datetime.now(tz=datetime.UTC).isoformat(),\n        }\n        blob = bucket.blob(f\"prediction_{time}.json\")\n        blob.upload_from_string(json.dumps(data))\n        print(\"Prediction saved to GCP bucket.\")\n</code></pre>"},{"location":"bentoml_service/#captcha.bentoml_service.CaptchaClassifierService.predict","title":"predict","text":"<pre><code>predict(image: np.ndarray) -&gt; np.ndarray\n</code></pre> <p>Predict the class of the input image.</p> Source code in <code>src/captcha/bentoml_service.py</code> <pre><code>@bentoml.api(\n    batchable=True,\n    batch_dim=(0, 0),\n    max_batch_size=128,\n    max_latency_ms=1000,\n)\ndef predict(self, image: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Predict the class of the input image.\"\"\"\n    request_counter.inc()\n    with request_latency.time():\n        try:\n            image_size_summary.observe(image.shape[2] * image.shape[3])\n            output = self.model.run(None, {\"input\": image.astype(np.float32)})\n            class_names = np.array(\n                [\"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"m\", \"n\", \"p\", \"w\", \"x\", \"y\"]\n            )\n            self.save_prediction_to_gcp(image, output[0][0].tolist(), class_names[np.argmax(output[0][0])])\n            return output[0]\n        except Exception as e:\n            error_counter.inc()\n            raise HTTPException(status_code=500, detail=str(e)) from e\n</code></pre>"},{"location":"bentoml_service/#captcha.bentoml_service.CaptchaClassifierService.save_prediction_to_gcp","title":"save_prediction_to_gcp","text":"<pre><code>save_prediction_to_gcp(image: np.ndarray, outputs: list[float], prediction: str) -&gt; None\n</code></pre> <p>Save the prediction results to GCP bucket.</p> Source code in <code>src/captcha/bentoml_service.py</code> <pre><code>def save_prediction_to_gcp(self, image: np.ndarray, outputs: list[float], prediction: str) -&gt; None:\n    \"\"\"Save the prediction results to GCP bucket.\"\"\"\n    client = storage.Client.create_anonymous_client()\n    bucket = client.bucket(\"mlops_captcha_monitoring\")\n    time = datetime.datetime.now(tz=datetime.UTC)\n    # Prepare prediction data\n    image = image.squeeze(0).squeeze(0)\n    image = image.flatten().tolist()\n    data = {\n        \"image\": image,\n        \"prediction\": prediction,\n        \"probability\": outputs,\n        \"timestamp\": datetime.datetime.now(tz=datetime.UTC).isoformat(),\n    }\n    blob = bucket.blob(f\"prediction_{time}.json\")\n    blob.upload_from_string(json.dumps(data))\n    print(\"Prediction saved to GCP bucket.\")\n</code></pre>"},{"location":"data/","title":"Data","text":""},{"location":"data/#captcha.data.preprocess","title":"captcha.data.preprocess","text":"<pre><code>preprocess() -&gt; None\n</code></pre> <p>Preprocess the CAPTCHA dataset.</p> Source code in <code>src/captcha/data.py</code> <pre><code>def preprocess() -&gt; None:\n    \"\"\"Preprocess the CAPTCHA dataset.\"\"\"\n    download_extract_dataset_dvc(RAW_DATA_PATH)\n\n    # Preprocess the data\n    logger.info(\"\\033[36mPreprocessing data...\")\n    preprocess_raw(RAW_DATA_PATH, PROCESSED_DATA_PATH, subset_size=len(list(RAW_DATA_PATH.glob(\"**/*.png\"))))\n    logger.success(\"\\033[32m \u2705Data preprocessing complete.\")\n\n    # Push processed data to DVC and check success\n    if push_data_to_dvc(PROCESSED_DATA_PATH):\n        logger.success(\"\\033[32m\u2705 Data preprocessing and DVC push complete.\")\n    else:\n        logger.error(\"\\033[31m\u274c Data preprocessing complete but DVC push failed.\")\n</code></pre>"},{"location":"dataset/","title":"Dataset","text":""},{"location":"dataset/#captcha.dataset.CaptchaDataset","title":"captcha.dataset.CaptchaDataset","text":"<p>               Bases: <code>Dataset</code></p> <p>Custom dataset for the CAPTCHA data.</p> Source code in <code>src/captcha/dataset.py</code> <pre><code>class CaptchaDataset(Dataset):\n    \"\"\"Custom dataset for the CAPTCHA data.\"\"\"\n\n    def __init__(self, processed_data_path: Path, data_type: str, state: str) -&gt; None:\n        \"\"\"\n        Initialize the dataset with the given path to processed data.\n        \"\"\"\n        self.data_path = processed_data_path\n        self.data_type = data_type\n        self.state = state\n        self.load_data()\n\n    def load_data(self) -&gt; None:\n        \"\"\"Return train, validation and test datasets for CAPTCHA data set.\"\"\"\n        if self.state == \"local\":\n            if self.data_type == \"train\":\n                self.images = torch.load(f\"{self.data_path}/train_images.pt\")\n                self.target = torch.load(f\"{self.data_path}/train_labels.pt\")\n            elif self.data_type == \"validation\" or self.data_type == \"val\":\n                self.images = torch.load(f\"{self.data_path}/val_images.pt\")\n                self.target = torch.load(f\"{self.data_path}/val_labels.pt\")\n            else:\n                self.images = torch.load(f\"{self.data_path}/test_images.pt\")\n                self.target = torch.load(f\"{self.data_path}/test_labels.pt\")\n        elif self.state == \"remote\":\n            client = storage.Client()\n            bucket = client.get_bucket(\"mlops_captcha_bucket\")\n            base_path = \"data/processed\"  # Base path in GCS bucket\n\n            if self.data_type == \"train\":\n                image_blob = bucket.blob(f\"{base_path}/train_images.pt\")\n                target_blob = bucket.blob(f\"{base_path}/train_labels.pt\")\n            elif self.data_type == \"validation\" or self.data_type == \"val\":\n                image_blob = bucket.blob(f\"{base_path}/val_images.pt\")\n                target_blob = bucket.blob(f\"{base_path}/val_labels.pt\")\n            else:\n                image_blob = bucket.blob(f\"{base_path}/test_images.pt\")\n                target_blob = bucket.blob(f\"{base_path}/test_labels.pt\")\n\n            self.images = torch.load(io.BytesIO(image_blob.download_as_bytes()))\n            self.target = torch.load(io.BytesIO(target_blob.download_as_bytes()))\n\n        return self.images, self.target\n\n    def __getitem__(self, idx: int) -&gt; tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"Return image and target tensor.\"\"\"\n        return self.images[idx], self.target[idx]\n\n    def __len__(self) -&gt; int:\n        \"\"\"Return the number of images in the dataset.\"\"\"\n        return self.images.shape[0]\n</code></pre>"},{"location":"dataset/#captcha.dataset.CaptchaDataset.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(idx: int) -&gt; tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Return image and target tensor.</p> Source code in <code>src/captcha/dataset.py</code> <pre><code>def __getitem__(self, idx: int) -&gt; tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Return image and target tensor.\"\"\"\n    return self.images[idx], self.target[idx]\n</code></pre>"},{"location":"dataset/#captcha.dataset.CaptchaDataset.__init__","title":"__init__","text":"<pre><code>__init__(processed_data_path: Path, data_type: str, state: str) -&gt; None\n</code></pre> <p>Initialize the dataset with the given path to processed data.</p> Source code in <code>src/captcha/dataset.py</code> <pre><code>def __init__(self, processed_data_path: Path, data_type: str, state: str) -&gt; None:\n    \"\"\"\n    Initialize the dataset with the given path to processed data.\n    \"\"\"\n    self.data_path = processed_data_path\n    self.data_type = data_type\n    self.state = state\n    self.load_data()\n</code></pre>"},{"location":"dataset/#captcha.dataset.CaptchaDataset.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Return the number of images in the dataset.</p> Source code in <code>src/captcha/dataset.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"Return the number of images in the dataset.\"\"\"\n    return self.images.shape[0]\n</code></pre>"},{"location":"dataset/#captcha.dataset.CaptchaDataset.load_data","title":"load_data","text":"<pre><code>load_data() -&gt; None\n</code></pre> <p>Return train, validation and test datasets for CAPTCHA data set.</p> Source code in <code>src/captcha/dataset.py</code> <pre><code>def load_data(self) -&gt; None:\n    \"\"\"Return train, validation and test datasets for CAPTCHA data set.\"\"\"\n    if self.state == \"local\":\n        if self.data_type == \"train\":\n            self.images = torch.load(f\"{self.data_path}/train_images.pt\")\n            self.target = torch.load(f\"{self.data_path}/train_labels.pt\")\n        elif self.data_type == \"validation\" or self.data_type == \"val\":\n            self.images = torch.load(f\"{self.data_path}/val_images.pt\")\n            self.target = torch.load(f\"{self.data_path}/val_labels.pt\")\n        else:\n            self.images = torch.load(f\"{self.data_path}/test_images.pt\")\n            self.target = torch.load(f\"{self.data_path}/test_labels.pt\")\n    elif self.state == \"remote\":\n        client = storage.Client()\n        bucket = client.get_bucket(\"mlops_captcha_bucket\")\n        base_path = \"data/processed\"  # Base path in GCS bucket\n\n        if self.data_type == \"train\":\n            image_blob = bucket.blob(f\"{base_path}/train_images.pt\")\n            target_blob = bucket.blob(f\"{base_path}/train_labels.pt\")\n        elif self.data_type == \"validation\" or self.data_type == \"val\":\n            image_blob = bucket.blob(f\"{base_path}/val_images.pt\")\n            target_blob = bucket.blob(f\"{base_path}/val_labels.pt\")\n        else:\n            image_blob = bucket.blob(f\"{base_path}/test_images.pt\")\n            target_blob = bucket.blob(f\"{base_path}/test_labels.pt\")\n\n        self.images = torch.load(io.BytesIO(image_blob.download_as_bytes()))\n        self.target = torch.load(io.BytesIO(target_blob.download_as_bytes()))\n\n    return self.images, self.target\n</code></pre>"},{"location":"dataset/#captcha.dataset.dataset_statistics","title":"captcha.dataset.dataset_statistics","text":"<pre><code>dataset_statistics(datadir: str = 'data/processed') -&gt; None\n</code></pre> Source code in <code>src/captcha/dataset.py</code> <pre><code>def dataset_statistics(datadir: str = \"data/processed\") -&gt; None:\n    train_dataset = CaptchaDataset(datadir, \"train\", state=STATE)\n    val_dataset = CaptchaDataset(datadir, \"validation\", state=STATE)\n    test_dataset = CaptchaDataset(datadir, \"test\", state=STATE)\n    class_names = np.array(torch.load(f\"{datadir}/class_names.pt\"))\n\n    print(\"Train dataset:\")\n    print(f\"Number of images: {len(train_dataset)}\")\n    print(f\"Image shape: {train_dataset[0][0].shape}\")\n    print(\"\\n\")\n    print(\"Validation dataset:\")\n    print(f\"Number of images: {len(val_dataset)}\")\n    print(f\"Image shape: {val_dataset[0][0].shape}\")\n    print(\"\\n\")\n    print(\"Test dataset:\")\n    print(f\"Number of images: {len(test_dataset)}\")\n    print(f\"Image shape: {test_dataset[0][0].shape}\")\n    print(\"\\n\")\n    print(f\"Class names: {class_names}\")\n\n    show_image_and_target(train_dataset.images[:25], class_names[train_dataset.target[:25].data.numpy()], show=False)\n    plt.savefig(\"captcha_images.png\")\n    plt.close()\n\n    train_label_distribution = torch.bincount(train_dataset.target)\n    val_label_distribution = torch.bincount(val_dataset.target)\n    test_label_distribution = torch.bincount(test_dataset.target)\n\n    plt.bar(class_names, train_label_distribution)\n    plt.title(\"Train label distribution\")\n    plt.xlabel(\"Label\")\n    plt.ylabel(\"Count\")\n    plt.savefig(\"train_label_distribution.png\")\n    plt.close()\n\n    plt.bar(class_names, val_label_distribution)\n    plt.title(\"Validation label distribution\")\n    plt.xlabel(\"Label\")\n    plt.ylabel(\"Count\")\n    plt.savefig(\"val_label_distribution.png\")\n    plt.close()\n\n    plt.bar(class_names, test_label_distribution)\n    plt.title(\"Test label distribution\")\n    plt.xlabel(\"Label\")\n    plt.ylabel(\"Count\")\n    plt.savefig(\"test_label_distribution.png\")\n    plt.close()\n</code></pre>"},{"location":"dataset/#captcha.dataset.show_image_and_target","title":"captcha.dataset.show_image_and_target","text":"<pre><code>show_image_and_target(images: torch.Tensor, target: np.array, show: bool = True) -&gt; None\n</code></pre> <p>Show images and target labels.</p> Source code in <code>src/captcha/dataset.py</code> <pre><code>def show_image_and_target(images: torch.Tensor, target: np.array, show: bool = True) -&gt; None:\n    \"\"\"Show images and target labels.\"\"\"\n    fig, axes = plt.subplots(5, 5, figsize=(10, 10))\n    for i, ax in enumerate(axes.flat):\n        ax.imshow(images[i].squeeze(), cmap=\"gray\")\n        ax.set_title(f\"Label: {target[i]}\")\n        ax.axis(\"off\")\n    if show:\n        plt.show()\n</code></pre>"},{"location":"evaluate/","title":"Evaluate","text":""},{"location":"evaluate/#captcha.evaluate.evaluate","title":"captcha.evaluate.evaluate","text":"<pre><code>evaluate(cfg: DictConfig) -&gt; None\n</code></pre> <p>Evaluates the model on the test set.</p> Source code in <code>src/captcha/evaluate.py</code> <pre><code>def evaluate(cfg: DictConfig) -&gt; None:\n    \"\"\"Evaluates the model on the test set.\"\"\"\n    with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n        data_path = f\"{_ROOT}/data/processed/\"\n        test_set = CaptchaDataset(data_path, \"test\", \"local\")\n        # _, _, test_set = load_dummy()\n        test_dataloader = torch.utils.data.DataLoader(test_set, batch_size=cfg.model.hyperparameters[\"batch_size\"])\n        model = Resnet18(cfg.optimizer.Adam_opt)  # this is our LightningModule\n        model_checkpoint = f\"{_ROOT}/models/model.pth\"\n        model.load_state_dict(torch.load(model_checkpoint))\n\n        trainer = Trainer()  # this is our Trainer\n        trainer.test(model, test_dataloader)\n    print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n</code></pre>"},{"location":"model/","title":"Model","text":""},{"location":"model/#captcha.model.Resnet18","title":"captcha.model.Resnet18","text":"<p>               Bases: <code>LightningModule</code></p> <p>Resnet18 model.</p> Source code in <code>src/captcha/model.py</code> <pre><code>class Resnet18(pl.LightningModule):\n    \"\"\"Resnet18 model.\"\"\"\n\n    def __init__(self, optimimzer_cfg: DictConfig, num_classes: int = 20) -&gt; None:\n        super().__init__()\n\n        self.optimizer_cfg = optimimzer_cfg\n\n        # Create the ResNet18 model\n        self.model = timm.create_model(\"resnet18\", pretrained=True, in_chans=1)\n\n        # Freeze all parameters in the pretrained layers\n        for param in self.model.parameters():\n            param.requires_grad = False\n\n        # Replace the final fully connected layer with your custom layer\n        num_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(num_features, num_classes)\n\n        # Ensure the new fc layer's parameters are trainable\n        for param in self.model.fc.parameters():\n            param.requires_grad = True\n\n        self.loss_fn = nn.CrossEntropyLoss()\n\n    def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"Forward pass.\"\"\"\n        return self.model(x)\n\n    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor]) -&gt; torch.Tensor:\n        \"\"\"Training step.\"\"\"\n        img, target = batch\n        y_pred = self(img)\n        loss = self.loss_fn(y_pred, target)\n        acc = (target == y_pred.argmax(dim=-1)).float().mean()\n        self.log(\"train_loss\", loss, on_epoch=True)\n        self.log(\"train_acc\", acc, on_epoch=True)\n        # print(f\"Train loss: {loss}, Train accuracy: {acc}\")\n        return loss\n\n    def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor]) -&gt; None:\n        \"\"\"Validation step.\"\"\"\n        img, target = batch\n        y_pred = self(img)\n        loss = self.loss_fn(y_pred, target)\n        acc = (target == y_pred.argmax(dim=-1)).float().mean()\n        self.log(\"val_loss\", loss, on_epoch=True)\n        self.log(\"val_acc\", acc, on_epoch=True)\n        # print(f\"Val loss: {loss}, Val accuracy: {acc}\")\n\n    def test_step(self, batch: Tuple[torch.Tensor, torch.Tensor]) -&gt; None:\n        \"\"\"Test step.\"\"\"\n        img, target = batch\n        y_pred = self(img)\n        loss = self.loss_fn(y_pred, target)\n        acc = (target == y_pred.argmax(dim=-1)).float().mean()\n        self.log(\"test_loss\", loss)\n        self.log(\"test_acc\", acc)\n        # print(f\"Test loss: {loss}, Test accuracy: {acc}\")\n\n    def configure_optimizers(self) -&gt; torch.optim.Optimizer:\n        \"\"\"Configure optimizer.\"\"\"\n        return hydra.utils.instantiate(self.optimizer_cfg, params=self.parameters())\n\n    def on_train_epoch_end(self) -&gt; None:\n        \"\"\"Log training metrics at the end of each epoch.\"\"\"\n        train_loss = self.trainer.callback_metrics.get(\"train_loss\")\n        train_acc = self.trainer.callback_metrics.get(\"train_acc\")\n        if train_loss is not None and train_acc is not None:\n            logger.info(\n                f\"\\033[36m\ud83d\udd04 Epoch {self.trainer.current_epoch + 1}\\033[0m Training - \\033[33mLoss: {train_loss:.4f}\\033[0m | \\033[32mAccuracy: {train_acc:.4f}\\033[0m\"\n            )\n\n    def on_validation_epoch_end(self) -&gt; None:\n        \"\"\"Log validation metrics at the end of each epoch.\"\"\"\n        val_loss = self.trainer.callback_metrics.get(\"val_loss\")\n        val_acc = self.trainer.callback_metrics.get(\"val_acc\")\n        if val_loss is not None and val_acc is not None:\n            logger.info(\n                f\"\\033[36m\u2705 Epoch {self.trainer.current_epoch + 1}\\033[0m Validation - \\033[33mLoss: {val_loss:.4f}\\033[0m | \\033[32mAccuracy: {val_acc:.4f}\\033[0m\"\n            )\n\n    def on_test_epoch_end(self) -&gt; None:\n        \"\"\"Log test metrics at the end of the test epoch.\"\"\"\n        test_loss = self.trainer.callback_metrics.get(\"test_loss\")\n        test_acc = self.trainer.callback_metrics.get(\"test_acc\")\n        if test_loss is not None and test_acc is not None:\n            logger.info(\n                f\"\\033[36m\ud83e\uddea Test Results\\033[0m - \\033[33mLoss: {test_loss:.4f}\\033[0m | \\033[32mAccuracy: {test_acc:.4f}\\033[0m\"\n            )\n\n    @classmethod\n    def load_from_checkpoint(cls, checkpoint_path: str, optimimzer_cfg: DictConfig, num_classes: int = 20):\n        if not os.path.exists(checkpoint_path):\n            raise FileNotFoundError(f\"Checkpoint file not found: {checkpoint_path}\")\n\n        # Initialize the model\n        model = cls(optimimzer_cfg=optimimzer_cfg, num_classes=num_classes)\n\n        # Load the checkpoint\n        checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n\n        # Directly load the weights\n        model.load_state_dict(checkpoint, strict=False)\n\n        model.eval()\n        return model\n</code></pre>"},{"location":"model/#captcha.model.Resnet18.configure_optimizers","title":"configure_optimizers","text":"<pre><code>configure_optimizers() -&gt; torch.optim.Optimizer\n</code></pre> <p>Configure optimizer.</p> Source code in <code>src/captcha/model.py</code> <pre><code>def configure_optimizers(self) -&gt; torch.optim.Optimizer:\n    \"\"\"Configure optimizer.\"\"\"\n    return hydra.utils.instantiate(self.optimizer_cfg, params=self.parameters())\n</code></pre>"},{"location":"model/#captcha.model.Resnet18.forward","title":"forward","text":"<pre><code>forward(x: torch.Tensor) -&gt; torch.Tensor\n</code></pre> <p>Forward pass.</p> Source code in <code>src/captcha/model.py</code> <pre><code>def forward(self, x: torch.Tensor) -&gt; torch.Tensor:\n    \"\"\"Forward pass.\"\"\"\n    return self.model(x)\n</code></pre>"},{"location":"model/#captcha.model.Resnet18.on_test_epoch_end","title":"on_test_epoch_end","text":"<pre><code>on_test_epoch_end() -&gt; None\n</code></pre> <p>Log test metrics at the end of the test epoch.</p> Source code in <code>src/captcha/model.py</code> <pre><code>def on_test_epoch_end(self) -&gt; None:\n    \"\"\"Log test metrics at the end of the test epoch.\"\"\"\n    test_loss = self.trainer.callback_metrics.get(\"test_loss\")\n    test_acc = self.trainer.callback_metrics.get(\"test_acc\")\n    if test_loss is not None and test_acc is not None:\n        logger.info(\n            f\"\\033[36m\ud83e\uddea Test Results\\033[0m - \\033[33mLoss: {test_loss:.4f}\\033[0m | \\033[32mAccuracy: {test_acc:.4f}\\033[0m\"\n        )\n</code></pre>"},{"location":"model/#captcha.model.Resnet18.on_train_epoch_end","title":"on_train_epoch_end","text":"<pre><code>on_train_epoch_end() -&gt; None\n</code></pre> <p>Log training metrics at the end of each epoch.</p> Source code in <code>src/captcha/model.py</code> <pre><code>def on_train_epoch_end(self) -&gt; None:\n    \"\"\"Log training metrics at the end of each epoch.\"\"\"\n    train_loss = self.trainer.callback_metrics.get(\"train_loss\")\n    train_acc = self.trainer.callback_metrics.get(\"train_acc\")\n    if train_loss is not None and train_acc is not None:\n        logger.info(\n            f\"\\033[36m\ud83d\udd04 Epoch {self.trainer.current_epoch + 1}\\033[0m Training - \\033[33mLoss: {train_loss:.4f}\\033[0m | \\033[32mAccuracy: {train_acc:.4f}\\033[0m\"\n        )\n</code></pre>"},{"location":"model/#captcha.model.Resnet18.on_validation_epoch_end","title":"on_validation_epoch_end","text":"<pre><code>on_validation_epoch_end() -&gt; None\n</code></pre> <p>Log validation metrics at the end of each epoch.</p> Source code in <code>src/captcha/model.py</code> <pre><code>def on_validation_epoch_end(self) -&gt; None:\n    \"\"\"Log validation metrics at the end of each epoch.\"\"\"\n    val_loss = self.trainer.callback_metrics.get(\"val_loss\")\n    val_acc = self.trainer.callback_metrics.get(\"val_acc\")\n    if val_loss is not None and val_acc is not None:\n        logger.info(\n            f\"\\033[36m\u2705 Epoch {self.trainer.current_epoch + 1}\\033[0m Validation - \\033[33mLoss: {val_loss:.4f}\\033[0m | \\033[32mAccuracy: {val_acc:.4f}\\033[0m\"\n        )\n</code></pre>"},{"location":"model/#captcha.model.Resnet18.test_step","title":"test_step","text":"<pre><code>test_step(batch: Tuple[torch.Tensor, torch.Tensor]) -&gt; None\n</code></pre> <p>Test step.</p> Source code in <code>src/captcha/model.py</code> <pre><code>def test_step(self, batch: Tuple[torch.Tensor, torch.Tensor]) -&gt; None:\n    \"\"\"Test step.\"\"\"\n    img, target = batch\n    y_pred = self(img)\n    loss = self.loss_fn(y_pred, target)\n    acc = (target == y_pred.argmax(dim=-1)).float().mean()\n    self.log(\"test_loss\", loss)\n    self.log(\"test_acc\", acc)\n</code></pre>"},{"location":"model/#captcha.model.Resnet18.training_step","title":"training_step","text":"<pre><code>training_step(batch: Tuple[torch.Tensor, torch.Tensor]) -&gt; torch.Tensor\n</code></pre> <p>Training step.</p> Source code in <code>src/captcha/model.py</code> <pre><code>def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor]) -&gt; torch.Tensor:\n    \"\"\"Training step.\"\"\"\n    img, target = batch\n    y_pred = self(img)\n    loss = self.loss_fn(y_pred, target)\n    acc = (target == y_pred.argmax(dim=-1)).float().mean()\n    self.log(\"train_loss\", loss, on_epoch=True)\n    self.log(\"train_acc\", acc, on_epoch=True)\n    # print(f\"Train loss: {loss}, Train accuracy: {acc}\")\n    return loss\n</code></pre>"},{"location":"model/#captcha.model.Resnet18.validation_step","title":"validation_step","text":"<pre><code>validation_step(batch: Tuple[torch.Tensor, torch.Tensor]) -&gt; None\n</code></pre> <p>Validation step.</p> Source code in <code>src/captcha/model.py</code> <pre><code>def validation_step(self, batch: Tuple[torch.Tensor, torch.Tensor]) -&gt; None:\n    \"\"\"Validation step.\"\"\"\n    img, target = batch\n    y_pred = self(img)\n    loss = self.loss_fn(y_pred, target)\n    acc = (target == y_pred.argmax(dim=-1)).float().mean()\n    self.log(\"val_loss\", loss, on_epoch=True)\n    self.log(\"val_acc\", acc, on_epoch=True)\n</code></pre>"},{"location":"train/","title":"Train","text":""},{"location":"train/#captcha.train.train","title":"captcha.train.train","text":"<pre><code>train(cfg: DictConfig) -&gt; None\n</code></pre> <p>Trains the model.</p> Source code in <code>src/captcha/train.py</code> <pre><code>def train(cfg: DictConfig) -&gt; None:\n    \"\"\"Trains the model.\"\"\"\n    logger.info(\"\\033[36m\ud83d\ude80 Starting training...\")\n    run = wandb.init(project=\"Captcha\")\n    data_path = f\"{_ROOT}/data/processed/\"\n    state = \"local\"\n    if not data_exists(data_path):\n        data_path = f\"{_ROOT}/gcs/mlops_captcha_bucket/data/processed\"\n        state = \"remote\"\n\n    # if not pull_data_from_dvc(data_path):\n    #    logger.error(\"\u274c Could not acquire processed data. Aborting training.\")\n    #    return\n\n    train_set = CaptchaDataset(data_path, \"train\", state)\n    validation_set = CaptchaDataset(data_path, \"validation\", state)\n    test_set = CaptchaDataset(data_path, \"test\", state)\n    # train_set, validation_set, test_set = load_dummy()\n    train_dataloader = torch.utils.data.DataLoader(\n        train_set,\n        batch_size=cfg.model.hyperparameters[\"batch_size\"],\n        shuffle=True,\n        num_workers=4,\n        persistent_workers=True,\n    )\n    validation_dataloader = torch.utils.data.DataLoader(\n        validation_set, batch_size=cfg.model.hyperparameters[\"batch_size\"], num_workers=4, persistent_workers=True\n    )\n    test_dataloader = torch.utils.data.DataLoader(\n        test_set, batch_size=cfg.model.hyperparameters[\"batch_size\"], num_workers=4, persistent_workers=True\n    )\n\n    model = Resnet18(cfg.optimizer.Adam_opt)  # LightningModule\n\n    trainer = pl.Trainer(\n        max_epochs=cfg.model.hyperparameters[\"epochs\"],\n        limit_train_batches=0.1,\n        limit_val_batches=0.1,\n        # callbacks=[early_stopping_callback],\n        logger=pl.loggers.WandbLogger(project=\"Captcha\"),\n        enable_progress_bar=False,\n    )  # Trainer\n    trainer.fit(model, train_dataloader, validation_dataloader)\n    logger.info(\"\\033[36m\ud83c\udfc1 Training completed. Starting testing...\")\n    trainer.test(model, test_dataloader)\n    logger.info(\"\\033\u2705 Testing completed\")\n    model_path = get_model_save_path()\n    torch.save(model.state_dict(), model_path)\n    logger.info(f\"\\033[36m\ud83d\udcbe Model saved to{model_path}\")\n\n    # Log model as an artifact\n    final_test_acc = trainer.callback_metrics.get(\"test_acc\", None)\n    final_test_loss = trainer.callback_metrics.get(\"test_loss\", None)\n    print(final_test_acc, final_test_loss)\n    artifact = wandb.Artifact(\n        name=\"captcha_model\",\n        type=\"model\",\n        description=\"A model trained to predict captcha images\",\n        metadata={\"test accuracy\": final_test_acc, \"test loss\": final_test_loss},\n    )\n\n    artifact.add_file(model_path)\n    run.log_artifact(artifact)\n</code></pre>"},{"location":"utils/","title":"Utils","text":""},{"location":"utils/#captcha.utils.normalize","title":"captcha.utils.normalize","text":"<pre><code>normalize(image: np.array) -&gt; np.array\n</code></pre> <p>Normalize an image by subtracting the mean and dividing by the standard deviation. Args:     images (np.array): Image. Returns:     np.array: Normalized image.</p> Source code in <code>src/captcha/utils.py</code> <pre><code>def normalize(image: np.array) -&gt; np.array:\n    \"\"\"\n    Normalize an image by subtracting the mean and dividing by the standard deviation.\n    Args:\n        images (np.array): Image.\n    Returns:\n        np.array: Normalized image.\n    \"\"\"\n    return (image - image.mean()) / image.std()\n</code></pre>"}]}